The following are some of the things that I have planned for this system.
-------------------------------------------------------------------------
A simple distributed system that should be able to run on arbitrary number of machines and be able to do simple operations (like multiplication of matrices).

Each slave machine is served with both the data and the "processor" to work with.
The slave machine has a client running which receives work units from its master and send the master a "message" when its done processing the work unit.

The master schedules the jobs (input by a user e.g.) and does load-balancing among its slaves. When all the work units are complete for a particular job,
the master "reduces" them to the required result.

No failure detection and work unit transfer are planned yet.

--[ Implementation
Each physical machine in a cluster is a "node".
All nodes in a cluster share the same configuration:
  - The slaves need the "master" part of the configuration file.
  - The master needs the "slave" part of the configuration file.

The node can be run in a number of modes e.g.
  - Master assign/reduce: This node will function as a master assigning work to
    its slaves. This master will take care of both splitting of work and
    assigning it to the slaves and receiving the results back and combining
    them into the final result.
  - Master assign: This node will only split/assign work among the slaves.
  - Master reduce: This node will only receive/reduce results received from
    the slaves.
  - Slave only: This node will function as a slave accepting work from the
    master, completing it, and sending the results back to master.

------[ Configuration file
A configuration file is needed by *each* node in the cluster. A configuration
file is a JSON file with the following mandatory sections:
  - The root dictionary must have at least the following keys:
    - master-combine: The master who is going to combine the results from the
      the slaves.
    - master-assign: The master who is going to assign task units to the slaves.
    - slaves: The list of slaves that are going to be assigned work by
      master-assign. Each slave value dictionary must have the following keys:
      - name: The hostname of the slave node.
      - ip: The ip address (as a dot-delimited string) of the slave node.
      - performance: The performance of a system on a relative scale.
    NOTE: master-assign and master-combine can be the same node.
    Each master-* value dictionary must have the following keys:
      - name: the hostname of the master node.
      - ip: the ip address (as a dot-delimited string) of the master node.
  - If the node is a master-* node, the slaves key must have a list of
    dictionaries as its value each of which represent a slave of the master.
  - If the node is a slave node, the slaves value must have its own node as
    one of the slaves.

------[ Serialization
The serialization scheme took some time to "implement in my head". The reason
being that I had to look carefully to see if it was possible to use some library
for python to serialize the objects. In particular, I need to serialize a task
unit and send it to a slave (from the master node). Now the complication here is
that the libraries provided by Python (e.g. pickle) can only serialize an
object to its "representation" and such libraries assume that the receiving end
will already have an idea of what this object is. In other words, they serialize
only the information about the metadata of a particular instance of an object.
For example if there as an object with a method inside it, then it cannot be
serialized by pickle.

So here's the method I came up with to "truly" serialize all the functionality
of an object assuming we already know the structure of the object:
First, I extract the code for the methods that I want to serialize from the
object like so:
<code>
import inspect

import taskunit

# Set the data and the processor.
tu = taskunit.TaskUnit("hello", lambda s: print(s))

method = tu.processor
# Get the source of the code as a string
method_code = inspect.getsource(method)
</code>

This gives us the source code of the required method.
Then I get all the other attributes of interest from the object and dump them
as a dictionary (including the data).
Then I construct a new dictionary with the following format:
<code>
{
  'processor' : 'def processor(x):\n    print(x * x)',
  'data': 4,
  'state': 'DEFINED'
   ...,
   ...,
   ...
}
</code>

This dictionary is then dumped as a JSON string and sent to the Slave (maybe
after compression). The slave then reads the JSON into Python lists/dictionaries
and extracts the required strings/values from the lists/dictionaries.
In particular, it extracts the processor's code. After doing so, it
"reconstructs" the TaskUnit object like so:

<code>
processor_string = decoded_json['processor']
data = decoded_json['data']
state_string = decoded_json['state']

exec(processor_string)
reconstructed_task_unit = TaskUnit(data_string, processor)
reconstructed_task_unit.state = state_string
</code>
The important part in this code above is the exec(...) call which basically
executes the code in the processor_string variable and defines the method
processor in the local scope. Then all we have to do is to create a new TaskUnit
and provide it with this processor and the data and that's basically it. If
there are other attributes that we also need to serialize, then we can also send
those through the JSON string over the network and decode on the Slave's end in
the same way as above.
